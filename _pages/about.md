---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<style>
    .experience-card {
        display: flex;
        align-items: center;
        background: #f9f9f9;
        border-radius: 12px;
        padding: 16px;
        margin-bottom: 0px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.05);
        transition: transform 0.3s, box-shadow 0.3s;
    }
    .experience-card:hover {
       
        box-shadow: 0 8px 16px rgba(0,0,0,0.1);
    }
    .experience-logo {
        width: 60px;
        height: 60px;
        margin-right: 20px;
        border-radius: 8px;
        object-fit: contain;
    }
    .experience-info {
        font-family: "Segoe UI", sans-serif;
    }
    .experience-info strong {
        font-size: 1.1em;
    }
    .experience-info a {
        text-decoration: none;
        color: #ca6f6f;
    }
    .experience-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
    }
    .experience-card {
        box-sizing: border-box;
    }
    .publication-card {
        display: flex;
        align-items: center;
        padding: 3px;
        border: 1.5px solid #ddd;
        border-radius: 8px;
        background: #fff;
        box-sizing: border-box;
        margin-bottom: 20px; 
        transition: transform 0.3s ease, box-shadow 0.3s ease;

        color: #5f6368; /* 正文整体更浅 */
    }
    .publication-card > div > strong,
    .publication-card > div > div > strong {
        color: #202124;
    }
    .publication-card i {
        color: #6b7280;
    }
    .publication-card:hover {
       
        box-shadow: 0 8px 16px rgba(0,0,0,0.1);
    }

    .publication-card.featured {
        border-color: #f5bba7;       /* 更浅的哈密瓜色边框 */
        background: #fef5f1;         /* 非常浅的哈密瓜色背景 */
        box-shadow: 0 4px 8px rgba(242, 166, 120, 0.2); /* 更柔和的初始阴影 */
        z-index: 10;
    }

    .publication-card.featured:hover {
        box-shadow: 0 8px 16px rgba(242, 166, 120, 0.4); 
    }
    
    .publication-card.non-featured {
        display: flex; /* 默认隐藏非精选出版物 */
    }
    
    .pub-button-container {
        display: flex;
        gap: 10px;
        margin: 20px 0;
        flex-wrap: wrap;
    }
    
    .pub-button {
        background-color: #f0f0f0;
        border: 1px solid #ccc;
        border-radius: 20px;
        padding: 8px 16px;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .pub-button:hover {
        background-color: #e0e0e0;
    }
    
    .pub-button.active {
        background-color: #ca6f6f;
        color: white;
        border-color: #ca6f6f;
    }

    /* Projects cards: keep styles independent from publications */
    .project-card {
        display: flex;
        align-items: center;
        padding: 3px;
        border: 1.5px solid #ddd;
        border-radius: 8px;
        background: #fff;
        box-sizing: border-box;
        margin-bottom: 20px;
        transition: transform 0.3s ease, box-shadow 0.3s ease;

        color: #5f6368;
    }

    .project-card > div > strong,
    .project-card > div > div > strong {
        color: #202124;
    }

    .project-card i {
        color: #6b7280;
    }

    .project-card:hover {
        box-shadow: 0 8px 16px rgba(0,0,0,0.1);
    }

</style>
<html> 
<head>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Permanent+Marker&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Fredericka+the+Great&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Homemade+Apple&display=swap');
        body {
            background-color:	 #FFFFFF;
            font-family: 'Arial Rounded MT Bold', 'Verdana', sans-serif;
            font-size: 15px;
        }
        .main-heading {
            font-family: 'Permanent Marker', cursive;
            text-align: center;
            color: #ca6f6f;
        }
        div.markdown-body a,a {
            text-decoration: none !important;
            color: #ca6f6f;
            transition: all 0.3s ease; /* 平滑过渡效果 */
        }
        div.markdown-body a:hover, a:hover {
            color: #c71585;            /* 悬浮时变深一点的颜色 */
            text-decoration: underline; /* 加上悬浮时的下划线 */
        }
    </style>
</head>
<body>
<h1 class="main-heading">Hi there <img src="../images/Hi.gif" width="40px"> Welcome to my Homepage!</h1>
</body>
</html>

- **Education**
  - Undergraduate Student, Nanjing University of Aeronautics and Astronautics, 2021–2025  
  - Master’s Student, Nanjing University, 2025–present  

- **Affiliation**
  - Postgraduate Researcher at [Websoft@NJU](http://ws.nju.edu.cn/wiki/Wiki.jsp?page=Websoft), advised by [Prof. Gong Cheng](http://ws.nju.edu.cn/wiki/Wiki.jsp?page=Gong%20Cheng)

- **Research Interests**
  - Reinforcement Learning (RL)
  - Large Language Model (LLM) Reasoning 
  - Vision-Language Model (VLM) Reasoning

News
---------------
- *[FlowGen](https://openreview.net/pdf?id=uimrBBfDCH) was accepted by ICLR 2026 &#128293;*
- *[FormulaReasoning](https://arxiv.org/pdf/2402.12692) is under review at ACL &#128293;*

Experience
--------------
 <div class="experience-container">
  <div class="experience-card">
      <img src="../images/NUAA.png" alt="NUAA logo" class="experience-logo">
      <div class="experience-info">
          <strong>Nanjing University of Aeronautics and Astronautics</strong><br>
          Sep 2021 - Jun 2025<br> Undergraduate Student, advised by <a href="https://lipiji.com/"><em>Prof. Piji Li</em></a>
      </div>
  </div>

  <div class="experience-card">
      <img src="../images/NJU.jpg" alt="NJU logo" class="experience-logo">
      <div class="experience-info">
          <strong>Nanjing University</strong><br>
          September 2025 - Now<br>
          M.S. Student at <a href="http://ws.nju.edu.cn/wiki/Wiki.jsp?page=Websoft"><em>Websoft@NJU</em></a>, advised by <a href="http://ws.nju.edu.cn/wiki/Wiki.jsp?page=Gong%20Cheng"><em>Prof. Gong Cheng</em></a>
      </div>
  </div>
  <div class="experience-card">
      <img src="../images/Lenovo2.png" alt="lenovo logo" class="experience-logo">
      <div class="experience-info">
          <strong>Lenovo Inc.</strong><br>
          April 2025 - Now<br>
          Supported by the CCF–Lenovo Blue Ocean Research Fund for research on flowchart parsing and QA.
      </div>
  </div>
</div>



Awards
--------------
- Suzhou Industrial Park Scholarship 2024 & 2025
- Outstanding Graduate, Nanjing University of Aeronautics and Astronautics, 2025


<!--
  <div class="experience-card">
      <img src="images/SJTU.png" alt="SJTU logo" class="experience-logo">
      <div class="experience-info">
          <strong>Shanghai Jiao Tong University</strong><br>
          July 2024 - June 2025<br>
          Research Intern at <a href="https://www.mvig.org/index.html"><em>MVIG</em></a> Lab
      </div>
  </div>-->
<!--
  <div class="experience-card">
      <img src="images/XDU.png" alt="Xi'dian logo" class="experience-logo">
      <div class="experience-info">
          <strong>Xidian University</strong><br>
          Sep 2022 - July 2026<br>
          Rank 4/174, <b>National Scholarship</b><br>
          B.E at <a href="https://sai.xidian.edu.cn"><em>SAI</em></a> & RA at <a href="https://web.xidian.edu.cn/mggong/"><em>OMEGA</em></a> Lab
      </div>
  </div>
</div>-->

<!--
Publications
--------------
<div class="pub-button-container">
  <button class="pub-button active" onclick="showPublications('all')">All Publications</button>
  <button class="pub-button" onclick="showPublications('featured')">Selected Only</button>
</div>

<div class="publication-card">
  <div style="display: flex; align-items: center;">
    <video width="200" height="120" style="margin-right: 20px; border-radius: 8px;" autoplay loop muted playsinline>
      <source src="images/clap.mp4" type="video/mp4">
    </video>
    <div>
        <strong>CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos</strong><br>
        <i style="font-size: 13px;">
            <a href="https://lin-shan.com/" target="_blank">Chubin Zhang</a>*,
            <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank">Jianan Wang</a>*, 
            <a href="" target="_blank">Zifeng Gao</a>, 
            <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>, 
            <a href="" target="_blank">Tiranru Dai</a>,
            <a href="https://homepage.zhouc.ai/" target="_blank">Cai Zhou</a>, <br>
            <a href="https://ivg.au.tsinghua.edu.cn/Jiwen_Lu/" target="_blank">Jiwen Lu</a>,
            <a href="https://andytang15.github.io/" target="_blank">Yansong Tang</a>&dagger;
        </i><br>
        Learning Vision-Language-Action Models from Human Videos.
        <br>
        <b><i style="color:#83a1c7;">ArXiv Preprint &nbsp;</i></b>
        <a href="https://arxiv.org/abs/2601.04061"><em>[arXiv]</em></a>
        <a href=""><em>[code]</em></a>
        <a href="https://lin-shan.com/CLAP/#"><em>[website]</em></a>
    </div>
  </div>
</div>

<div class="publication-card featured">
  <div style="display: flex; align-items: center;">
    <video width="200" height="120" style="margin-right: 20px; border-radius: 8px;" autoplay loop muted playsinline>
      <source src="images/dspv2.mp4" type="video/mp4">
    </video>
    <div>
        <strong>DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation</strong><br>
        <i style="font-size: 13px;">
            <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>, 
            <a href="https://lin-shan.com/" target="_blank">Chubin Zhang</a>, 
            <a href="https://ch3cook-fdu.github.io/" target="_blank">Sijin Chen</a>,
            <a href="" target="_blank">Liufan Tan</a>, <br>
            <a href="https://andytang15.github.io/" target="_blank">Yansong Tang</a>,
            <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank">Jianan Wang</a>,
            <a href="https://xh-liu.github.io/" target="_blank">Xihui Liu</a>&dagger;
        </i><br>
        Improved Dense Policy for Whole-body Mobile Manipulation, with effective perception, generalizable manipulation and coherent actions.
        <br>
        <b><i style="color:#83a1c7;">ICRA 2026 &nbsp;</i></b>
        <a href="https://arxiv.org/abs/2509.16063"><em>[arXiv]</em></a>
        <a href="https://github.com/Selen-Suyue/DSPv2"><em>[code]</em></a>
        <a href="https://selen-suyue.github.io/DSPv2Net/"><em>[website]</em></a>
    </div>
  </div>
</div>

<div class="publication-card featured">
 <div style="display: flex; align-items: center;">
    <video width="200" height="120" style="margin-right: 20px; border-radius: 8px;" autoplay loop muted playsinline>
      <source src="images/flower_dsp.mp4" type="video/mp4">
    </video>
    <div>
        <strong>Dense Policy: Bidirectional Autoregressive Learning of Actions</strong><br>
        <i style="font-size: 13px;">
            <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>*, 
            <a href="https://scholar.google.com/citations?user=WurpqEMAAAAJ&hl=en" target="_blank">Xinyu Zhan</a>*, 
            <a href="https://tonyfang.net/" target="_blank">Hongjie Fang</a>, 
            <a href="https://hanxue.me/" target="_blank">Han Xue</a>, <br>
            <a href="https://fang-haoshu.github.io/" target="_blank">Haoshu Fang</a>, 
            <a href="https://dirtyharrylyl.github.io/" target="_blank">Yong-Lu Li</a>, 
            <a href="http://mvig.org" target="_blank">Cewu Lu</a>, 
            <a href="https://lixiny.github.io" target="_blank">Lixin Yang</a>&dagger;
        </i><br>
        Propose Dense Policy, A bidirectional robotic autoregressive policy, which infers trajectories by gradually expanding actions from sparse keyframes, demonstrated exceeding diffusion policies.<br>
        <b><i style="color:#83a1c7;">ICCV 2025 &nbsp;</i></b>
        <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Su_Dense_Policy_Bidirectional_Autoregressive_Learning_of_Actions_ICCV_2025_paper.html"><em>[paper]</em></a>
        <a href="https://arxiv.org/abs/2503.13217"><em>[arXiv]</em></a>
        <a href="https://selen-suyue.github.io/DspNet/"><em>[website]</em></a>
        <a href="https://github.com/Selen-Suyue/DensePolicy"><em>[3D-code]</em></a>
        <a href="https://github.com/Selen-Suyue/DensePolicy2D"><em>[2D-code]</em></a>
    </div>
</div>
</div>

<div class="publication-card featured">
 <div style="display: flex; align-items: center;">
    <img src="images/mba_animation.gif" alt="MBA" width="200" height="100" style="margin-right: 20px;">
    <div>
        <strong>Motion Before Action: Diffusing Object Motion as Manipulation Condition</strong><br>
        <i style="font-size: 13px;">
            <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>*, 
            <a href="https://scholar.google.com/citations?user=WurpqEMAAAAJ&hl=en" target="_blank">Xinyu Zhan</a>*, 
            <a href="https://tonyfang.net/" target="_blank">Hongjie Fang</a>, 
            <a href="https://dirtyharrylyl.github.io/" target="_blank">Yong-Lu Li</a>, 
            <a href="http://mvig.org" target="_blank">Cewu Lu</a>, 
            <a href="https://lixiny.github.io" target="_blank">Lixin Yang</a>&dagger;
        </i><br>
        Propose MBA, a novel plug-and-play module leveraging cascaded diffusion processes to generate actions guided by object motion, enabling seamless integration with manipulation policies.<br>
      <b><i style="color:#83a1c7;">RA-L 2025, ICRA 2026 &nbsp;</i></b>
        <a href="https://ieeexplore.ieee.org/abstract/document/11027642"><em>[paper]</em></a>
        <a href="https://arxiv.org/abs/2411.09658"><em>[arxiv]</em></a> 
        <a href="https://selen-suyue.github.io/MBApage"><em>[website]</em></a>
        <a href="https://github.com/Selen-Suyue/MBA"><em>[code]</em></a>
    </div>
</div>
</div>

<div class="publication-card non-featured">
    <img src="images/GAP.png" alt="RIaa" width="200" height="100" style="margin-right: 20px;">
    <div>
        <strong>Generative Adversarial Patches for Physical Attacks on Cross-Modal Pedestrian Re-Identification</strong><br>
       <i style="font-size: 13px;">
    <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>, 
    <a href="https://scholar.google.com/citations?user=JkQmO-kAAAAJ&hl=en" target="_blank">Hao Li</a>&dagger;, 
    <a href="https://web.xidian.edu.cn/mggong/" target="_blank">Maoguo Gong</a>&dagger;
    </i><br>
    A generative physical adversarial attack on VI-ReID models perturbs modality-invariant features. <br>
    <b><i style="color:#83a1c7;">ArXiv Preprint &nbsp;</i></b>
      <a href="https://arxiv.org/abs/2410.20097"><em>[arxiv]</em></a>
    </div>
</div>

<div class="publication-card non-featured">
    <img src="images/iraa.png" alt="Raa" width="200" height="100" style="margin-right: 20px;">
    <div>
        <strong>AdvDisplay: Adversarial Display Assembled by Thermoelectric Cooler for Fooling Thermal Infrared Detectors</strong><br>
      <i style="font-size: 13px;">
    <a href="https://scholar.google.com/citations?user=JkQmO-kAAAAJ&hl=en" target="_blank">Hao Li</a>&dagger;, 
    <a href="https://scholar.google.com/citations?user=eX7Ra5UAAAAJ&hl=en" target="_blank">Fanggao Wan</a>, 
    <a href="https://selen-suyue.github.io" target="_blank"><strong>Yue Su</strong></a>, 
    <a href="https://ywuchina.github.io/" target="_blank">Yue Wu</a>, 
    <a href="https://scholar.google.com/citations?user=h4PExPwAAAAJ&hl=en" target="_blank">Mingyang Zhang</a>, 
    <a href="https://web.xidian.edu.cn/mggong/" target="_blank">Maoguo Gong</a>&dagger;
    </i><br>
      Historically, infrared adversarial attacks were single-use and tough to deploy. Using TEC, we implemented efficient attacks adaptable to hardware scenarios.
      <br>
      <b><i style="color:#83a1c7;">AAAI 2025 &nbsp;</i></b>
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34011"><em>[paper]</em></a>
    </div>
</div>

<script src="assets/js/show_publications.js"></script>

Projects
--------
<div class="project-card">
 <div style="display: flex; align-items: center;">
    <img src="images/maniunicon.png" alt="Maniunicon" width="200" height="100" style="margin-right: 20px;">
    <div>
        <strong>ManiUniCon: A Unified Control Interface for Robotic Manipulation</strong><br>
ManiUniCon is a comprehensive, multi-process robotics control framework designed for robotic manipulation tasks. It provides a unified interface for controlling various robot arms, integrating sensors, and executing policies in real-time. <br>
      <a href="https://github.com/Universal-Control/ManiUniCon"><em>[code]</em></a>
    </div>
</div>
</div>
<div class="project-card">
 <div style="display: flex; align-items: center;">
    <img src="images/MetaPalace.png" alt="MetaPalace" width="200" height="100" style="margin-right: 20px;">
    <div>
        <strong>MetaPalace: Let you in a meta world of The Palace Museum</strong><br>
We've done what the Old Palace official website couldn't: offering 3D artifact views with single-view reconstruction and an interactive LLM-powered tour guider using RAG technology. <br>
      <a href="https://metapalace.xj63.fun/"><em>[website]</em></a> 
      <a href="https://github.com/xj63/MetaPalaceSite"><em>[front-end code]</em></a>
      <a href="https://github.com/Selen-Suyue/MetaPalace"><em>[back-end code]</em></a>
    </div>
</div>
</div>


Talks
--------
- [2025/12] Invited to [Talk on NICE seminar](https://www.bilibili.com/video/BV1utBrBfED4?spm_id_from=333.788.videopod.episodes&p=9) about Imitation Learning
- [2025/12] Invited to [Talk on RL China](https://b23.tv/We6FLQh) about DSPv2
- [2025/10] Invited to [Talk on 3D视觉工坊](https://b23.tv/PvLKNR1) about DSP and DSPv2
-->
